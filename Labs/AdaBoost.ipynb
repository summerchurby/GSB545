{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: PA - AdaBoost\n",
    "author: Summer Churby\n",
    "format: \n",
    "        html: \n",
    "            toc: true\n",
    "            code-fold: true\n",
    "embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment Specs\n",
    "\n",
    "You should compare AdaBoost to at least one of the following: a bagging model, a stacking model.\n",
    "Based on the visualizations seen at the links above you're probably also thinking that this classification task should not be that difficult. So, a secondary goal of this assignment is to test the effects of the AdaBoost function arguments on the algorithm's performance. \n",
    "You should explore at least 3 different sets of settings for the function inputs, and you should do your best to find values for these inputs that actually change the results of your modelling. That is, try not to run three different sets of inputs that result in the same performance. The goal here is for you to better understand how to set these input values yourself in the future. Comment on what you discover about these inputs and how the behave.\n",
    "Your submission should be built and written with non-experts as the target audience. All of your code should still be included, but do your best to narrate your work in accessible ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "import pandas as pd\n",
    "penguins = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\penguins_size.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Test Accuracy: 98.51 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "penguins = penguins.dropna()\n",
    "for label in penguins.columns:\n",
    "    penguins[label] = LabelEncoder().fit_transform(penguins[label])\n",
    "\n",
    "X = penguins.drop(['species'], axis=1)\n",
    "Y = penguins['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "base_tree = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "bagging = BaggingClassifier(estimator=base_tree, n_estimators=100, random_state=42)\n",
    "\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bagging.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Bagging Test Accuracy:\", round(accuracy * 100, 2), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  98.50746268656717 %\n"
     ]
    }
   ],
   "source": [
    "# first adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "for label in penguins.columns:\n",
    "    penguins[label] = LabelEncoder().fit(penguins[label]).transform(penguins[label])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "    \n",
    "X = penguins.drop(['species'],axis=1)\n",
    "Y = penguins['species']\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='entropy',max_depth=1)\n",
    "\n",
    "\n",
    "AdaBoost = AdaBoostClassifier(n_estimators=400,learning_rate=1,algorithm='SAMME')\n",
    "\n",
    "AdaBoost.fit(X_train, y_train)\n",
    "prediction = AdaBoost.score(X_test, y_test)\n",
    "\n",
    "print('The accuracy is: ',prediction*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  97.60479041916167 %\n"
     ]
    }
   ],
   "source": [
    "# second adaboost - higher estimator and lower learning rate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=6)\n",
    "X = penguins.drop(['species'],axis=1)\n",
    "Y = penguins['species']\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "AdaBoost = AdaBoostClassifier(estimator=model, n_estimators=500, learning_rate=0.4, algorithm='SAMME')\n",
    "AdaBoost.fit(X_train, y_train)\n",
    "prediction = AdaBoost.score(X_test, y_test)\n",
    "\n",
    "print('The accuracy is: ',prediction*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\achur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\achur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\achur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\achur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated accuracy: 98.8 %\n"
     ]
    }
   ],
   "source": [
    "# third adaboost - using cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "X = penguins.drop(['species'],axis=1)\n",
    "Y = penguins['species']\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "AdaBoost = AdaBoostClassifier(estimator=model, n_estimators=500, learning_rate=0.4, algorithm='SAMME')\n",
    "scores = cross_val_score(AdaBoost, X, Y, cv=5)\n",
    "print(\"Cross-validated accuracy:\", round(scores.mean() * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each different model that was run, all of the predicted accuracies were very close. For the first model, I ran a straight boosting classifier and got a 98.51% accuracy. For the first boosting model, I ran a straight boosting model with an estimator of 400 and a learning rate of 1 and got an accuracy of 98.057%. For the second adaboost model, I changed did a test size of 0.5 instead of 0.2 and changed the seed as well as changing the estimator to 500 and the learning rate to 0.4 and got an accuracy of 97.60%. For the third adaboost model, I added in cross validation and got an accuracy of 98.8%. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
