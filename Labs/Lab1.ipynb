{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Lab 1 - Bagging and Stacking\n",
    "author: Summer Churby\n",
    "format: \n",
    "        html: \n",
    "            toc: true\n",
    "            code-fold: true\n",
    "embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a relatively simple dataset, but your goal is this: \n",
    "\n",
    "Can we predict Sleep Score (posted by the FitBit app) using the other metrics in the dataset? In other words, is there a formula here that the FitBit app uses to compute Sleep Score that we can reverse-engineer?\n",
    "Two constraints for this assignment:\n",
    "\n",
    "1. Your modeling efforts must involve bagging and stacking in some way. Otherwise, you may try whatever you like.\n",
    "\n",
    "2. You are allowed, even encouraged, to compute and/or gather additional features to use as explanatory variables in your model. For example, you might create a variable for the time they went to sleep (as a measure of how \"early\" they went to bed, or not). There are multiple datasets and you should use all of them, which means you may use the corresponding month for the dataset as a variable as well (or anything related to it).\n",
    "\n",
    "Your submission should be an HTML or .ipynb file of all of your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load in files\n",
    "april_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\April sleep data - Sheet1.csv\")\n",
    "december_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\December Sleep data - Sheet1.csv\")\n",
    "february_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\February sleep data - Sheet1 (1).csv\")\n",
    "january_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\January sleep data - Sheet1.csv\")\n",
    "march_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\March sleep data - Sheet1.csv\")\n",
    "november_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\November Sleep Data - Sheet1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "\n",
    "# rename sleep score in feb df\n",
    "february_df.rename(columns={\"SLEEP SQORE\": \"SLEEP SCORE\"}, inplace=True)\n",
    "\n",
    "# rename the february column\n",
    "february_df.rename(columns={\"FEBEUARY\": \"FEBRUARY\"}, inplace=True)\n",
    "\n",
    "# rename column for days of the week\n",
    "february_df.rename(columns={\"FEBRUARY\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "april_df.rename(columns={\"APRIL\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "december_df.rename(columns={\"DECEMBER\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "january_df.rename(columns={\"JANUARY\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "march_df.rename(columns={\"MARCH\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "november_df.rename(columns={\"NOVEMBER\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "\n",
    "# then create month column\n",
    "april_df[\"MONTH\"] = \"APRIL\"\n",
    "february_df[\"MONTH\"] = \"FEBRUARY\"\n",
    "december_df[\"MONTH\"] = \"DECEMBER\"\n",
    "january_df[\"MONTH\"] = \"JANUARY\"\n",
    "march_df[\"MONTH\"] = \"MARCH\"\n",
    "november_df[\"MONTH\"] = \"NOVEMBER\"\n",
    "\n",
    "\n",
    "# heart rate in below resting and under resting\n",
    "january_df.rename(columns={\"HEART RATE UNDER RESTING\": \"HEART RATE BELOW RESTING\"}, inplace=True)\n",
    "\n",
    "# march for heart rate and heartrate\n",
    "march_df.rename(columns={\"HEARTRATE BELOW RESTING\": \"HEART RATE BELOW RESTING\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop na's\n",
    "april_df.dropna(inplace=True)\n",
    "february_df.dropna(inplace=True)\n",
    "december_df.dropna(inplace=True)\n",
    "january_df.dropna(inplace=True)\n",
    "march_df.dropna(inplace=True)\n",
    "november_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the dataframes\n",
    "df_combined = pd.concat([april_df, february_df, december_df, january_df, march_df, november_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-56>:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<positron-console-cell-56>:18: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
     ]
    }
   ],
   "source": [
    "# fix the times\n",
    "import re\n",
    "\n",
    "df_combined[[\"SLEEP START\", \"SLEEP END\"]] = df_combined[\"SLEEP TIME\"].str.split(\" - \", expand=True)\n",
    "\n",
    "def fix_time_string(s):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"(\\d{1,2})-(\\d{2})(am|pm)\", r\"\\1:\\2\\3\", s)  \n",
    "    s = re.sub(r\"[^\\dxapm:]\", \"\", s)  \n",
    "    return s\n",
    "\n",
    "df_combined[\"SLEEP START\"] = df_combined[\"SLEEP START\"].apply(fix_time_string)\n",
    "df_combined[\"SLEEP END\"] = df_combined[\"SLEEP END\"].apply(fix_time_string)\n",
    "\n",
    "df_combined[\"SLEEP START\"] = pd.to_datetime(df_combined[\"SLEEP START\"], errors=\"coerce\").dt.strftime(\"%H:%M\")\n",
    "df_combined[\"SLEEP END\"] = pd.to_datetime(df_combined[\"SLEEP END\"], errors=\"coerce\").dt.strftime(\"%H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the times so that all of them have seconds\n",
    "df_combined['HOURS OF SLEEP'] = df_combined['HOURS OF SLEEP'].apply(\n",
    "    lambda x: x if len(x.split(':')) == 3 else f\"{x}:00\"\n",
    ")\n",
    "# convert to hours of sleep\n",
    "df_combined['HOURS OF SLEEP'] = pd.to_timedelta(df_combined['HOURS OF SLEEP']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure percentages are floats\n",
    "for col in ['REM SLEEP', 'DEEP SLEEP', 'HEART RATE BELOW RESTING']:\n",
    "    df_combined[col] = df_combined[col].str.replace('%', '').astype(float)\n",
    "\n",
    "# convert sleep start and end to hours\n",
    "df_combined['SLEEP START'] = pd.to_datetime(df_combined['SLEEP START'].astype(str), format='%H:%M', errors='coerce')\n",
    "df_combined['SLEEP END'] = pd.to_datetime(df_combined['SLEEP END'].astype(str), format='%H:%M', errors='coerce')\n",
    "\n",
    "# make sure hours and minutes are floats\n",
    "df_combined['SLEEP START'] = df_combined['SLEEP START'].dt.hour + df_combined['SLEEP START'].dt.minute / 60\n",
    "df_combined['SLEEP END'] = df_combined['SLEEP END'].dt.hour + df_combined['SLEEP END'].dt.minute / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and Stacking Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging MSE: 5.61\n",
      "Stacking MSE: 5.75\n",
      "Average Predicted Sleep Score (Bagging): 84.48\n",
      "Average Predicted Sleep Score (Stacking): 84.28\n",
      "\n",
      "Bagging CV MSE: 31.26\n",
      "\n",
      "Stacking CV MSE: 32.62\n",
      "Bagging CV RMSE: 5.59\n",
      "Stacking CV RMSE: 5.71\n",
      "Bagging R² Score: 0.6808\n",
      "Stacking R² Score: 0.6727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# dummify variables\n",
    "df_combined = pd.get_dummies(df_combined, columns=['MONTH', 'DAYS OF THE WEEK'], drop_first=True)\n",
    "\n",
    "# Drop unused or problematic columns\n",
    "#df.drop(columns=['DATE', 'SLEEP TIME'], inplace=True)\n",
    "#df.dropna(inplace=True)\n",
    "\n",
    "# x and y\n",
    "X = df_combined.drop(columns=['SLEEP SCORE', 'DATE', 'SLEEP TIME'], errors='ignore')\n",
    "y = df_combined['SLEEP SCORE']\n",
    "\n",
    "# standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# bagging model\n",
    "bagging_model = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(),\n",
    "    n_estimators=100,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# check bagging model\n",
    "bagging_model.fit(X_train, y_train)\n",
    "y_pred_bag = bagging_model.predict(X_test)\n",
    "mse_bag = mean_squared_error(y_test, y_pred_bag)\n",
    "print(f\"Bagging MSE: {mse_bag:.2f}\")\n",
    "\n",
    "# stacking model using bagging\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('bagging', bagging_model),\n",
    "        ('knn', KNeighborsRegressor())\n",
    "    ],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "# check stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "mse_stack = mean_squared_error(y_test, y_pred_stack)\n",
    "\n",
    "print(f\"Stacking MSE: {mse_stack:.2f}\")\n",
    "#prediction\n",
    "\n",
    "y_pred_bag = bagging_model.predict(X_test)\n",
    "avg_bagging_score = y_pred_bag.mean()\n",
    "print(f\"Average Predicted Sleep Score (Bagging): {avg_bagging_score:.2f}\")\n",
    "\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "avg_stacking_score = y_pred_stack.mean()\n",
    "print(f\"Average Predicted Sleep Score (Stacking): {avg_stacking_score:.2f}\")\n",
    "\n",
    "# cv bag\n",
    "bagging_cv_scores = cross_val_score(\n",
    "    bagging_model, X_scaled, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "bagging_cv_mse = -np.mean(bagging_cv_scores)\n",
    "bagging_cv_std = np.std(bagging_cv_scores)\n",
    "print(f\"\\nBagging CV MSE: {bagging_cv_mse:.2f}\")\n",
    "\n",
    "# cv stack\n",
    "stacking_cv_scores = cross_val_score(\n",
    "    stacking_model, X_scaled, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "stacking_cv_mse = -np.mean(stacking_cv_scores)\n",
    "stacking_cv_std = np.std(stacking_cv_scores)\n",
    "print(f\"\\nStacking CV MSE: {stacking_cv_mse:.2f}\")\n",
    "rmse_bag = np.sqrt(bagging_cv_mse)\n",
    "rmse_stack = np.sqrt(stacking_cv_mse)\n",
    "print(f\"Bagging CV RMSE: {rmse_bag:.2f}\")\n",
    "print(f\"Stacking CV RMSE: {rmse_stack:.2f}\")\n",
    "# r2 for Bagging\n",
    "r2_bag = r2_score(y_test, y_pred_bag)\n",
    "print(f\"Bagging R² Score: {r2_bag:.4f}\")\n",
    "\n",
    "# r2 for Stacking\n",
    "r2_stack = r2_score(y_test, y_pred_stack)\n",
    "print(f\"Stacking R² Score: {r2_stack:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bagging model had the highest R^2 value, so it is best fitting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix and References\n",
    "https://docs.python.org/3/library/re.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html\n",
    "\n",
    "Generative A.I. Statement: Chat-GPT was used to suggest changes in code to debug errors. Chat-GPT was only used to resolve errors in already hand written code."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
