{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load in files\n",
    "april_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\April sleep data - Sheet1.csv\")\n",
    "december_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\December Sleep data - Sheet1.csv\")\n",
    "february_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\February sleep data - Sheet1 (1).csv\")\n",
    "january_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\January sleep data - Sheet1.csv\")\n",
    "march_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\March sleep data - Sheet1.csv\")\n",
    "november_df = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Spring 2024\\545\\GSB545\\Labs\\November Sleep Data - Sheet1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "\n",
    "# rename sleep score in feb df\n",
    "february_df.rename(columns={\"SLEEP SQORE\": \"SLEEP SCORE\"}, inplace=True)\n",
    "\n",
    "# rename the february column\n",
    "february_df.rename(columns={\"FEBEUARY\": \"FEBRUARY\"}, inplace=True)\n",
    "\n",
    "# rename column for days of the week\n",
    "february_df.rename(columns={\"FEBRUARY\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "april_df.rename(columns={\"APRIL\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "december_df.rename(columns={\"DECEMBER\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "january_df.rename(columns={\"JANUARY\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "march_df.rename(columns={\"MARCH\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "november_df.rename(columns={\"NOVEMBER\": \"DAYS OF THE WEEK\"}, inplace=True)\n",
    "\n",
    "# then create month column\n",
    "april_df[\"MONTH\"] = \"APRIL\"\n",
    "february_df[\"MONTH\"] = \"FEBRUARY\"\n",
    "december_df[\"MONTH\"] = \"DECEMBER\"\n",
    "january_df[\"MONTH\"] = \"JANUARY\"\n",
    "march_df[\"MONTH\"] = \"MARCH\"\n",
    "november_df[\"MONTH\"] = \"NOVEMBER\"\n",
    "\n",
    "\n",
    "# heart rate in below resting anad under resting\n",
    "january_df.rename(columns={\"HEART RATE UNDER RESTING\": \"HEART RATE BELOW RESTING\"}, inplace=True)\n",
    "\n",
    "# march for heart rate and heartrate\n",
    "march_df.rename(columns={\"HEARTRATE BELOW RESTING\": \"HEART RATE BELOW RESTING\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop na's\n",
    "april_df.dropna(inplace=True)\n",
    "february_df.dropna(inplace=True)\n",
    "december_df.dropna(inplace=True)\n",
    "january_df.dropna(inplace=True)\n",
    "march_df.dropna(inplace=True)\n",
    "november_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the dataframes\n",
    "df_combined = pd.concat([april_df, february_df, december_df, january_df, march_df, november_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-64>:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<positron-console-cell-64>:18: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
     ]
    }
   ],
   "source": [
    "# fix the times\n",
    "import re\n",
    "\n",
    "df_combined[[\"SLEEP START\", \"SLEEP END\"]] = df_combined[\"SLEEP TIME\"].str.split(\" - \", expand=True)\n",
    "\n",
    "def fix_time_string(s):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"(\\d{1,2})-(\\d{2})(am|pm)\", r\"\\1:\\2\\3\", s)  \n",
    "    s = re.sub(r\"[^\\dxapm:]\", \"\", s)  \n",
    "    return s\n",
    "\n",
    "df_combined[\"SLEEP START\"] = df_combined[\"SLEEP START\"].apply(fix_time_string)\n",
    "df_combined[\"SLEEP END\"] = df_combined[\"SLEEP END\"].apply(fix_time_string)\n",
    "\n",
    "df_combined[\"SLEEP START\"] = pd.to_datetime(df_combined[\"SLEEP START\"], errors=\"coerce\").dt.strftime(\"%H:%M\")\n",
    "df_combined[\"SLEEP END\"] = pd.to_datetime(df_combined[\"SLEEP END\"], errors=\"coerce\").dt.strftime(\"%H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the times so that all of them have seconds\n",
    "df_combined['HOURS OF SLEEP'] = df_combined['HOURS OF SLEEP'].apply(\n",
    "    lambda x: x if len(x.split(':')) == 3 else f\"{x}:00\"\n",
    ")\n",
    "# convert to hours of sleep\n",
    "df_combined['HOURS OF SLEEP'] = pd.to_timedelta(df_combined['HOURS OF SLEEP']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure percentages are floats\n",
    "for col in ['REM SLEEP', 'DEEP SLEEP', 'HEART RATE BELOW RESTING']:\n",
    "    df_combined[col] = df_combined[col].str.replace('%', '').astype(float)\n",
    "\n",
    "# convert sleep start and end to hours\n",
    "df_combined['SLEEP START'] = pd.to_datetime(df_combined['SLEEP START'].astype(str), format='%H:%M', errors='coerce')\n",
    "df_combined['SLEEP END'] = pd.to_datetime(df_combined['SLEEP END'].astype(str), format='%H:%M', errors='coerce')\n",
    "\n",
    "# make sure hours and minutes are floats\n",
    "df_combined['SLEEP START'] = df_combined['SLEEP START'].dt.hour + df_combined['SLEEP START'].dt.minute / 60\n",
    "df_combined['SLEEP END'] = df_combined['SLEEP END'].dt.hour + df_combined['SLEEP END'].dt.minute / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and Stacking Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging MAE: 1.82\n",
      "Stacking MAE: 1.82\n",
      "Average Predicted Sleep Score (Bagging): 84.47\n",
      "Average Predicted Sleep Score (Stacking): 84.23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# dummify variables\n",
    "df_combined = pd.get_dummies(df_combined, columns=['MONTH', 'DAYS OF THE WEEK'], drop_first=True)\n",
    "\n",
    "# Drop unused or problematic columns\n",
    "#df.drop(columns=['DATE', 'SLEEP TIME'], inplace=True)\n",
    "#df.dropna(inplace=True)\n",
    "\n",
    "# x and y\n",
    "X = df_combined.drop(columns=['SLEEP SCORE', 'DATE', 'SLEEP TIME'], errors='ignore')\n",
    "y = df_combined['SLEEP SCORE']\n",
    "\n",
    "# standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# bagging model\n",
    "bagging_model = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(),\n",
    "    n_estimators=50,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# check bagging model\n",
    "bagging_model.fit(X_train, y_train)\n",
    "y_pred_bag = bagging_model.predict(X_test)\n",
    "mae_bag = mean_absolute_error(y_test, y_pred_bag)\n",
    "print(f\"Bagging MAE: {mae_bag:.2f}\")\n",
    "\n",
    "# stacking model using bagging\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('bagging', bagging_model),\n",
    "        ('knn', KNeighborsRegressor())\n",
    "    ],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "# check stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "mae_stack = mean_absolute_error(y_test, y_pred_stack)\n",
    "\n",
    "print(f\"Stacking MAE: {mae_stack:.2f}\")\n",
    "#prediction\n",
    "\n",
    "y_pred_bag = bagging_model.predict(X_test)\n",
    "avg_bagging_score = y_pred_bag.mean()\n",
    "print(f\"Average Predicted Sleep Score (Bagging): {avg_bagging_score:.2f}\")\n",
    "\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "avg_stacking_score = y_pred_stack.mean()\n",
    "print(f\"Average Predicted Sleep Score (Stacking): {avg_stacking_score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
